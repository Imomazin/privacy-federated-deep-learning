{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1fx0zPkBPsJ",
        "outputId": "ffef976c-d49f-4ce0-99da-98d7576a879d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:11<00:00, 15.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Partition stats\n",
            "Total train samples: 50000\n",
            "Clients: 50\n",
            "Samples per client: min=281 max=1836 mean=1000.0 std=374.2\n",
            "\n",
            "Initial | test_loss=2.3031 test_acc=11.09%\n",
            "\n",
            "Round 1/10\n",
            "  test_loss=2.3156 test_acc=13.54%\n",
            "\n",
            "Round 2/10\n",
            "  test_loss=2.3326 test_acc=10.00%\n",
            "\n",
            "Round 3/10\n",
            "  test_loss=2.3127 test_acc=16.48%\n",
            "\n",
            "Round 4/10\n",
            "  test_loss=2.2128 test_acc=15.21%\n",
            "\n",
            "Round 5/10\n",
            "  test_loss=2.1549 test_acc=21.29%\n",
            "\n",
            "Round 6/10\n",
            "  test_loss=2.0967 test_acc=22.32%\n",
            "\n",
            "Round 7/10\n",
            "  test_loss=2.1304 test_acc=20.39%\n",
            "\n",
            "Round 8/10\n",
            "  test_loss=2.0562 test_acc=19.88%\n",
            "\n",
            "Round 9/10\n",
            "  test_loss=2.0874 test_acc=21.96%\n",
            "\n",
            "Round 10/10\n",
            "  test_loss=2.0791 test_acc=21.29%\n",
            "\n",
            "FEDAVG CIFAR-10 Non-IID BASELINE FINISHED\n",
            "Saved:\n",
            " - results_fedavg_cifar10_non_iid/metrics.csv\n",
            " - results_fedavg_cifar10_non_iid/training_curves.png\n",
            " - results_fedavg_cifar10_non_iid/final_model.pt\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# FEDAVG CIFAR-10 NON-IID BASELINE (NO DP, NO OPACUS)\n",
        "# Single-cell, fresh, runnable in Google Colab\n",
        "# ==============================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------\n",
        "# 0) Repro + Device\n",
        "# ------------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Config\n",
        "# ------------------------------\n",
        "CONFIG = {\n",
        "    \"seed\": SEED,\n",
        "    \"dataset\": \"CIFAR-10\",\n",
        "    \"num_clients\": 50,\n",
        "    \"clients_per_round\": 10,\n",
        "    \"rounds\": 10,                 # increase to 50-200 later\n",
        "    \"local_epochs\": 1,            # increase to 2-5 later\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.01,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \"dirichlet_alpha\": 0.5,       # lower = more Non-IID\n",
        "    \"test_batch_size\": 256,\n",
        "    \"results_dir\": \"results_fedavg_cifar10_non_iid\",\n",
        "}\n",
        "\n",
        "RESULTS_DIR = CONFIG[\"results_dir\"]\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(RESULTS_DIR, \"config.json\"), \"w\") as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Data\n",
        "# ------------------------------\n",
        "transform_train = T.Compose([\n",
        "    T.RandomCrop(32, padding=4),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform_train\n",
        ")\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"test_batch_size\"], shuffle=False, num_workers=2)\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Non-IID partition: Dirichlet over classes\n",
        "# ------------------------------\n",
        "def dirichlet_partition(dataset, num_clients: int, alpha: float, num_classes: int = 10, seed: int = 42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    targets = np.array(dataset.targets)\n",
        "\n",
        "    class_indices = [np.where(targets == y)[0] for y in range(num_classes)]\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idx_c = class_indices[c]\n",
        "        rng.shuffle(idx_c)\n",
        "\n",
        "        proportions = rng.dirichlet(alpha * np.ones(num_clients))\n",
        "        # convert proportions to counts\n",
        "        counts = (proportions * len(idx_c)).astype(int)\n",
        "\n",
        "        # fix rounding so sum(counts) == len(idx_c)\n",
        "        diff = len(idx_c) - counts.sum()\n",
        "        for i in rng.choice(num_clients, size=abs(diff), replace=True):\n",
        "            counts[i] += 1 if diff > 0 else -1\n",
        "        # guard against negative\n",
        "        counts = np.clip(counts, 0, None)\n",
        "\n",
        "        start = 0\n",
        "        for k in range(num_clients):\n",
        "            take = counts[k]\n",
        "            if take > 0:\n",
        "                client_indices[k].extend(idx_c[start:start+take].tolist())\n",
        "                start += take\n",
        "\n",
        "    # shuffle within each client\n",
        "    for k in range(num_clients):\n",
        "        rng.shuffle(client_indices[k])\n",
        "\n",
        "    return client_indices\n",
        "\n",
        "client_indices = dirichlet_partition(\n",
        "    train_dataset,\n",
        "    num_clients=CONFIG[\"num_clients\"],\n",
        "    alpha=CONFIG[\"dirichlet_alpha\"],\n",
        "    num_classes=10,\n",
        "    seed=CONFIG[\"seed\"]\n",
        ")\n",
        "\n",
        "sizes = [len(ix) for ix in client_indices]\n",
        "print(\"\\nPartition stats\")\n",
        "print(\"Total train samples:\", len(train_dataset))\n",
        "print(\"Clients:\", CONFIG[\"num_clients\"])\n",
        "print(f\"Samples per client: min={min(sizes)} max={max(sizes)} mean={np.mean(sizes):.1f} std={np.std(sizes):.1f}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 4) Model (simple CNN that matches CIFAR-10 shape)\n",
        "# ------------------------------\n",
        "class CIFAR10CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 32x32\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 32x32\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                             # 16x16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# 16x16\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                             # 8x8\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 8 * 8, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# ------------------------------\n",
        "# 5) Utils: evaluation + FedAvg\n",
        "# ------------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, loader: DataLoader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_sum = 0.0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y, reduction=\"sum\")\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "def get_client_loader(cid: int):\n",
        "    subset = Subset(train_dataset, client_indices[cid])\n",
        "    return DataLoader(subset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=2, drop_last=False)\n",
        "\n",
        "def train_one_client(global_state: dict, cid: int):\n",
        "    model = CIFAR10CNN().to(DEVICE)\n",
        "    model.load_state_dict(global_state)\n",
        "    model.train()\n",
        "\n",
        "    loader = get_client_loader(cid)\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=CONFIG[\"lr\"],\n",
        "        momentum=CONFIG[\"momentum\"],\n",
        "        weight_decay=CONFIG[\"weight_decay\"]\n",
        "    )\n",
        "\n",
        "    for _ in range(CONFIG[\"local_epochs\"]):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "def fedavg(states: list):\n",
        "    # states: list of state_dicts (CPU tensors)\n",
        "    avg = {}\n",
        "    for k in states[0].keys():\n",
        "        avg[k] = torch.zeros_like(states[0][k])\n",
        "    for sd in states:\n",
        "        for k in avg.keys():\n",
        "            avg[k] += sd[k] / len(states)\n",
        "    return avg\n",
        "\n",
        "# ------------------------------\n",
        "# 6) Federated training loop\n",
        "# ------------------------------\n",
        "global_model = CIFAR10CNN().to(DEVICE)\n",
        "metrics = []\n",
        "\n",
        "init_loss, init_acc = evaluate(global_model, test_loader)\n",
        "print(f\"\\nInitial | test_loss={init_loss:.4f} test_acc={init_acc*100:.2f}%\")\n",
        "\n",
        "for rnd in range(1, CONFIG[\"rounds\"] + 1):\n",
        "    print(f\"\\nRound {rnd}/{CONFIG['rounds']}\")\n",
        "\n",
        "    selected = random.sample(range(CONFIG[\"num_clients\"]), CONFIG[\"clients_per_round\"])\n",
        "    global_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "    client_states = []\n",
        "    for cid in selected:\n",
        "        cs = train_one_client(global_state, cid)\n",
        "        client_states.append(cs)\n",
        "\n",
        "    new_global_state = fedavg(client_states)\n",
        "    global_model.load_state_dict(new_global_state)\n",
        "\n",
        "    test_loss, test_acc = evaluate(global_model, test_loader)\n",
        "    print(f\"  test_loss={test_loss:.4f} test_acc={test_acc*100:.2f}%\")\n",
        "    metrics.append([rnd, test_loss, test_acc])\n",
        "\n",
        "# ------------------------------\n",
        "# 7) Save outputs\n",
        "# ------------------------------\n",
        "metrics_path = os.path.join(RESULTS_DIR, \"metrics.csv\")\n",
        "with open(metrics_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"round\", \"test_loss\", \"test_accuracy\"])\n",
        "    writer.writerows(metrics)\n",
        "\n",
        "model_path = os.path.join(RESULTS_DIR, \"final_model.pt\")\n",
        "torch.save(global_model.state_dict(), model_path)\n",
        "\n",
        "rounds = [m[0] for m in metrics]\n",
        "losses = [m[1] for m in metrics]\n",
        "accs = [m[2] for m in metrics]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(rounds, accs)\n",
        "plt.title(\"Test Accuracy\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(rounds, losses)\n",
        "plt.title(\"Test Loss\")\n",
        "\n",
        "fig_path = os.path.join(RESULTS_DIR, \"training_curves.png\")\n",
        "plt.savefig(fig_path)\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nFEDAVG CIFAR-10 Non-IID BASELINE FINISHED\")\n",
        "print(\"Saved:\")\n",
        "print(\" -\", metrics_path)\n",
        "print(\" -\", fig_path)\n",
        "print(\" -\", model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# FEDAVG CIFAR-10 NON-IID BASELINE\n",
        "# ===============================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLIENTS = 10\n",
        "CLIENTS_PER_ROUND = 5\n",
        "ROUNDS = 10\n",
        "LOCAL_EPOCHS = 1\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.01\n",
        "RESULTS_DIR = \"results_fedavg_cifar10_non_iid\"\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# -------------------------------\n",
        "# DATA\n",
        "# -------------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# -------------------------------\n",
        "# NON-IID SPLIT (label skew)\n",
        "# -------------------------------\n",
        "def non_iid_split(dataset, num_clients):\n",
        "    labels = np.array(dataset.targets)\n",
        "    idxs = np.arange(len(dataset))\n",
        "    idxs_labels = np.vstack((idxs, labels))\n",
        "    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
        "    idxs = idxs_labels[0]\n",
        "\n",
        "    shards = np.array_split(idxs, num_clients)\n",
        "    return {i: shards[i] for i in range(num_clients)}\n",
        "\n",
        "client_indices = non_iid_split(train_dataset, NUM_CLIENTS)\n",
        "\n",
        "# -------------------------------\n",
        "# MODEL (FIXED DIMENSIONS)\n",
        "# -------------------------------\n",
        "class CIFAR10CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # ✅ FIX\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# -------------------------------\n",
        "# TRAIN ONE CLIENT\n",
        "# -------------------------------\n",
        "def train_one_client(global_state, cid):\n",
        "    model = CIFAR10CNN().to(DEVICE)\n",
        "    model.load_state_dict(global_state)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
        "\n",
        "    loader = DataLoader(\n",
        "        Subset(train_dataset, client_indices[cid]),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for _ in range(LOCAL_EPOCHS):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model.state_dict()\n",
        "\n",
        "# -------------------------------\n",
        "# EVALUATION\n",
        "# -------------------------------\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct, total, loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            out = model(x)\n",
        "            loss_sum += F.cross_entropy(out, y, reduction=\"sum\").item()\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "# -------------------------------\n",
        "# FEDERATED TRAINING\n",
        "# -------------------------------\n",
        "global_model = CIFAR10CNN().to(DEVICE)\n",
        "metrics = []\n",
        "\n",
        "for rnd in range(1, ROUNDS + 1):\n",
        "    print(f\"\\nRound {rnd}/{ROUNDS}\")\n",
        "\n",
        "    selected = random.sample(range(NUM_CLIENTS), CLIENTS_PER_ROUND)\n",
        "    global_state = global_model.state_dict()\n",
        "\n",
        "    agg_state = {k: torch.zeros_like(v) for k, v in global_state.items()}\n",
        "\n",
        "    for cid in selected:\n",
        "        local_state = train_one_client(global_state, cid)\n",
        "        for k in agg_state:\n",
        "            agg_state[k] += local_state[k] / CLIENTS_PER_ROUND\n",
        "\n",
        "    global_model.load_state_dict(agg_state)\n",
        "\n",
        "    loss, acc = evaluate(global_model)\n",
        "    metrics.append([rnd, loss, acc])\n",
        "    print(f\"Test Acc: {acc*100:.2f}% | Loss: {loss:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# SAVE RESULTS\n",
        "# -------------------------------\n",
        "with open(os.path.join(RESULTS_DIR, \"metrics.csv\"), \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Round\", \"Loss\", \"Accuracy\"])\n",
        "    writer.writerows(metrics)\n",
        "\n",
        "torch.save(\n",
        "    global_model.state_dict(),\n",
        "    os.path.join(RESULTS_DIR, \"final_model.pt\")\n",
        ")\n",
        "\n",
        "rounds = [m[0] for m in metrics]\n",
        "accs = [m[2] for m in metrics]\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(rounds, accs)\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.title(\"FedAvg CIFAR-10 Non-IID Baseline\")\n",
        "plt.savefig(os.path.join(RESULTS_DIR, \"training_curves.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nFEDAVG CIFAR-10 NON-IID BASELINE FINISHED\")\n",
        "print(\"Saved:\")\n",
        "print(f\"- {RESULTS_DIR}/metrics.csv\")\n",
        "print(f\"- {RESULTS_DIR}/training_curves.png\")\n",
        "print(f\"- {RESULTS_DIR}/final_model.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-b6o6z9hRvu",
        "outputId": "2fd107e0-e3d5-4bf6-dbcc-150dc4b6c09e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 73.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1/10\n",
            "Test Acc: 10.00% | Loss: 2.5301\n",
            "\n",
            "Round 2/10\n",
            "Test Acc: 11.57% | Loss: 2.5730\n",
            "\n",
            "Round 3/10\n",
            "Test Acc: 13.25% | Loss: 2.6168\n",
            "\n",
            "Round 4/10\n",
            "Test Acc: 10.79% | Loss: 2.7831\n",
            "\n",
            "Round 5/10\n",
            "Test Acc: 10.66% | Loss: 2.8081\n",
            "\n",
            "Round 6/10\n",
            "Test Acc: 9.93% | Loss: 2.7666\n",
            "\n",
            "Round 7/10\n",
            "Test Acc: 10.71% | Loss: 2.8367\n",
            "\n",
            "Round 8/10\n",
            "Test Acc: 12.63% | Loss: 2.6903\n",
            "\n",
            "Round 9/10\n",
            "Test Acc: 10.30% | Loss: 2.6871\n",
            "\n",
            "Round 10/10\n",
            "Test Acc: 10.24% | Loss: 2.6997\n",
            "\n",
            "FEDAVG CIFAR-10 NON-IID BASELINE FINISHED\n",
            "Saved:\n",
            "- results_fedavg_cifar10_non_iid/metrics.csv\n",
            "- results_fedavg_cifar10_non_iid/training_curves.png\n",
            "- results_fedavg_cifar10_non_iid/final_model.pt\n"
          ]
        }
      ]
    }
  ]
}